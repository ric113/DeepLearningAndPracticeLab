# Lab3

## Objective
* Run a Caption generator by using CNN and RNN language generator trained on the COCO dataset to generate a sentence that describes the image.
* [Lab3 - Caption generation with visual attention](./lab3_image_caption.pdf)

## Report
* [Lab3 Report](./Report.pdf)

## Resources
* [GitHub - ImageCaptioning.pytorch](https://github.com/ruotianluo/ImageCaptioning.pytorch)
* [【图像理解】之Show, attend and tell算法详解](https://blog.csdn.net/shenxiaolu1984/article/details/51493673)
* [Multimodal —— 看图说话（Image Caption）任务的论文笔记（二）引入attention机制](https://www.cnblogs.com/Determined22/p/6914926.html)
* [《Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering》论文笔记](https://zhuanlan.zhihu.com/p/36151033)
* [GitHub - Attention visualization](https://github.com/alecwangcq/show-attend-and-tell/blob/master/visualize.ipynb)
* [NTU 李宏毅教授 ML lecture - RNN & LSTM introduction](https://www.youtube.com/watch?v=xCGidAeyS4M)
* [NTU 李宏毅教授 DL lecture - Conditional Generation by RNN & Attention](https://www.youtube.com/watch?v=f1KUUz7v8g4&list=PLJV_el3uVTsPMxPbjeX7PicgWbY7F8wW9&index=8)
    - Attention-based model example : 26:35